{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SCIKIT_LEARN_06_Classification_Metrics_Classification_Accuracy.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlmacedo/maxtrack/blob/master/notebooks/machine-learning/SCIKIT_LEARN_06_Classification_Metrics_Classification_Accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVP4mX7zbOm5",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating a classification model: Classification accuracy\n",
        "\n",
        "Created by [Data School](http://www.dataschool.io/). Modified by [David MacÃªdo](https://github.com/dlmacedo). **Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2cJpnpzbOm8",
        "colab_type": "text"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- What is the purpose of **model evaluation**, and what are some common evaluation procedures?\n",
        "- What is the usage of **classification accuracy**, and what are its limitations?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpGwVpmLbOm9",
        "colab_type": "text"
      },
      "source": [
        "## Review of model evaluation\n",
        "\n",
        "- Need a way to choose between models: different model types, tuning parameters, and features\n",
        "- Use a **model evaluation procedure** to estimate how well a model will generalize to out-of-sample data\n",
        "- Requires a **model evaluation metric** to quantify the model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ppIyM4bOm-",
        "colab_type": "text"
      },
      "source": [
        "### Model evaluation procedures\n",
        "\n",
        "1. **Training and testing on the same data**\n",
        "    - Rewards overly complex models that \"overfit\" the training data and won't necessarily generalize\n",
        "2. **Train/test split**\n",
        "    - Split the dataset into two pieces, so that the model can be trained and tested on different data\n",
        "    - Better estimate of out-of-sample performance, but still a \"high variance\" estimate\n",
        "    - Useful due to its speed, simplicity, and flexibility\n",
        "3. **K-fold cross-validation**\n",
        "    - Systematically create \"K\" train/test splits and average the results together\n",
        "    - Even better estimate of out-of-sample performance\n",
        "    - Runs \"K\" times slower than train/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nef5_zSAbOnA",
        "colab_type": "text"
      },
      "source": [
        "## Classification accuracy\n",
        "\n",
        "[Pima Indians Diabetes dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) originally from the UCI Machine Learning Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp0f1HLzbOnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the data into a pandas DataFrame\n",
        "import pandas as pd\n",
        "path = 'https://raw.githubusercontent.com/justmarkham/scikit-learn-videos/master/data/pima-indians-diabetes.data'\n",
        "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "pima = pd.read_csv(path, header=None, names=col_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgKtJ5FUbOnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the first 5 rows of data\n",
        "pima.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMN6JJBJbOnH",
        "colab_type": "text"
      },
      "source": [
        "**Question:** Can we predict the diabetes status of a patient given their health measurements?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQJpq6IQbOnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define X and y\n",
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
        "X = pima[feature_cols]\n",
        "y = pima.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pstvlbN-bOnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VdOe83_bOnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train a logistic regression model on the training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNVK31nWbOnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for the testing set\n",
        "y_pred_class = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDJocWpMbOnP",
        "colab_type": "text"
      },
      "source": [
        "**Classification accuracy:** percentage of correct predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8ieUTnmbOnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate accuracy\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ki7osvRbOnS",
        "colab_type": "text"
      },
      "source": [
        "**Null accuracy:** accuracy that could be achieved by always predicting the most frequent class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNgMxCnGbOnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine the class distribution of the testing set (using a Pandas Series method)\n",
        "y_test.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1uyWD59bOnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the percentage of ones\n",
        "y_test.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkVlTX6sbOnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the percentage of zeros\n",
        "1 - y_test.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk5SEfe4bOnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate null accuracy (for binary classification problems coded as 0/1)\n",
        "max(y_test.mean(), 1 - y_test.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E_iSswDbOna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate null accuracy (for multi-class classification problems)\n",
        "y_test.value_counts().head(1) / len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0ApUdE8bOnc",
        "colab_type": "text"
      },
      "source": [
        "Comparing the **true** and **predicted** response values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngC11r5IbOnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the first 25 true and predicted responses\n",
        "print('True:', y_test.values[0:25])\n",
        "print('Pred:', y_pred_class[0:25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClHliTZ1bOne",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "- Classification accuracy is the **easiest classification metric to understand**\n",
        "- But, it does not tell you the **underlying distribution** of response values\n",
        "- And, it does not tell you what **\"types\" of errors** your classifier is making"
      ]
    }
  ]
}