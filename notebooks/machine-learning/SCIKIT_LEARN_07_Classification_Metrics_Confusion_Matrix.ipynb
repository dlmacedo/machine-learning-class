{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SCIKIT_LEARN_07_Classification_Metrics_Confusion_Matrix.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlmacedo/maxtrack/blob/master/notebooks/machine-learning/SCIKIT_LEARN_07_Classification_Metrics_Confusion_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVP4mX7zbOm5",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating a classification model: Confusion matrix\n",
        "\n",
        "Created by [Data School](http://www.dataschool.io/). Modified by [David MacÃªdo](https://github.com/dlmacedo). **Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2cJpnpzbOm8",
        "colab_type": "text"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- How does a **confusion matrix** describe the performance of a classifier?\n",
        "- What **metrics** can be computed from a confusion matrix?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp0f1HLzbOnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the data into a pandas DataFrame\n",
        "import pandas as pd\n",
        "path = 'https://raw.githubusercontent.com/justmarkham/scikit-learn-videos/master/data/pima-indians-diabetes.data'\n",
        "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "pima = pd.read_csv(path, header=None, names=col_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgKtJ5FUbOnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the first 5 rows of data\n",
        "pima.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQJpq6IQbOnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define X and y\n",
        "feature_cols = ['pregnant', 'insulin', 'bmi', 'age']\n",
        "X = pima[feature_cols]\n",
        "y = pima.label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pstvlbN-bOnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VdOe83_bOnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train a logistic regression model on the training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNVK31nWbOnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for the testing set\n",
        "y_pred_class = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvjhEtJobOnf",
        "colab_type": "text"
      },
      "source": [
        "## Confusion matrix\n",
        "\n",
        "Table that describes the performance of a classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdItD0F5bOnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate accuracy\n",
        "from sklearn import metrics\n",
        "# IMPORTANT: first argument is true values, second argument is predicted values\n",
        "print(metrics.confusion_matrix(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J52HZhoWbOnj",
        "colab_type": "text"
      },
      "source": [
        "![Small confusion matrix](https://github.com/justmarkham/scikit-learn-videos/blob/master/images/09_confusion_matrix_1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvmQYzfRbOnk",
        "colab_type": "text"
      },
      "source": [
        "- Every observation in the testing set is represented in **exactly one box**\n",
        "- It's a 2x2 matrix because there are **2 response classes**\n",
        "- The format shown here is **not** universal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu7qmxw6bOnk",
        "colab_type": "text"
      },
      "source": [
        "**Basic terminology**\n",
        "\n",
        "- **True Positives (TP):** we *correctly* predicted that they *do* have diabetes\n",
        "- **True Negatives (TN):** we *correctly* predicted that they *don't* have diabetes\n",
        "- **False Positives (FP):** we *incorrectly* predicted that they *do* have diabetes (a \"Type I error\")\n",
        "- **False Negatives (FN):** we *incorrectly* predicted that they *don't* have diabetes (a \"Type II error\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YDwKevXbOnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the first 25 true and predicted responses\n",
        "print('True:', y_test.values[0:25])\n",
        "print('Pred:', y_pred_class[0:25])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdTlkGVGbOnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save confusion matrix and slice into four pieces\n",
        "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
        "TP = confusion[1, 1]\n",
        "TN = confusion[0, 0]\n",
        "FP = confusion[0, 1]\n",
        "FN = confusion[1, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaLCc5s-bOnq",
        "colab_type": "text"
      },
      "source": [
        "![Large confusion matrix](https://github.com/justmarkham/scikit-learn-videos/blob/master/images/09_confusion_matrix_2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n3sD2JKbOnq",
        "colab_type": "text"
      },
      "source": [
        "## Metrics computed from a confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sdrz8yCbOnr",
        "colab_type": "text"
      },
      "source": [
        "**Classification Accuracy:** Overall, how often is the classifier correct?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsBzR7R9bOns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((TP + TN) / float(TP + TN + FP + FN))\n",
        "print(metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2MFiowObOnt",
        "colab_type": "text"
      },
      "source": [
        "**Classification Error:** Overall, how often is the classifier incorrect?\n",
        "\n",
        "- Also known as \"Misclassification Rate\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luDzq_DqbOnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print((FP + FN) / float(TP + TN + FP + FN))\n",
        "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvz27hidbOnv",
        "colab_type": "text"
      },
      "source": [
        "**Sensitivity:** When the actual value is positive, how often is the prediction correct?\n",
        "\n",
        "- How \"sensitive\" is the classifier to detecting positive instances?\n",
        "- Also known as \"True Positive Rate\" or \"Recall\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Oiw-MCbOnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(TP / float(TP + FN))\n",
        "print(metrics.recall_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSW_Yhk6bOnx",
        "colab_type": "text"
      },
      "source": [
        "**Specificity:** When the actual value is negative, how often is the prediction correct?\n",
        "\n",
        "- How \"specific\" (or \"selective\") is the classifier in predicting positive instances?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgpwmJf2bOny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(TN / float(TN + FP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mZyJGdsbOnz",
        "colab_type": "text"
      },
      "source": [
        "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3vwj0CNbOn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(FP / float(TN + FP))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8LvTLnCbOn1",
        "colab_type": "text"
      },
      "source": [
        "**Precision:** When a positive value is predicted, how often is the prediction correct?\n",
        "\n",
        "- How \"precise\" is the classifier when predicting positive instances?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu6f_g9zbOn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(TP / float(TP + FP))\n",
        "print(metrics.precision_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkI4hojlbOn3",
        "colab_type": "text"
      },
      "source": [
        "Many other metrics can be computed: F1 score, Matthews correlation coefficient, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OkJLHsxbOn4",
        "colab_type": "text"
      },
      "source": [
        "**Conclusion:**\n",
        "\n",
        "- Confusion matrix gives you a **more complete picture** of how your classifier is performing\n",
        "- Also allows you to compute various **classification metrics**, and these metrics can guide your model selection\n",
        "\n",
        "**Which metrics should you focus on?**\n",
        "\n",
        "- Choice of metric depends on your **business objective**\n",
        "- **Spam filter** (positive class is \"spam\"): Optimize for **precision or specificity** because false negatives (spam goes to the inbox) are more acceptable than false positives (non-spam is caught by the spam filter)\n",
        "- **Fraudulent transaction detector** (positive class is \"fraud\"): Optimize for **sensitivity** because false positives (normal transactions that are flagged as possible fraud) are more acceptable than false negatives (fraudulent transactions that are not detected)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a_nxH55bOoe",
        "colab_type": "text"
      },
      "source": [
        "## Confusion Matrix Resources\n",
        "\n",
        "- Blog post: [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
        "- Videos: [Intuitive sensitivity and specificity](https://www.youtube.com/watch?v=U4_3fditnWg) (9 minutes) and [The tradeoff between sensitivity and specificity](https://www.youtube.com/watch?v=vtYDyGGeQyo) (13 minutes) by Rahul Patwari\n",
        "- Notebook: [How to calculate \"expected value\"](https://github.com/podopie/DAT18NYC/blob/master/classes/13-expected_value_cost_benefit_analysis.ipynb) from a confusion matrix by treating it as a cost-benefit matrix (by Ed Podojil)\n",
        "\n"
      ]
    }
  ]
}