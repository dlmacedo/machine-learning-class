{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SCIKIT_LEARN_04_Cross_Validation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlmacedo/maxtrack/blob/master/notebooks/machine-learning/SCIKIT_LEARN_04_Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zXK4qqwXXme",
        "colab_type": "text"
      },
      "source": [
        "# Cross-validation for parameter tuning, model selection, and feature selection\n",
        "\n",
        "Created by [Data School](http://www.dataschool.io/). Modified by [David MacÃªdo](https://github.com/dlmacedo). **Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAWKHmq-XXmh",
        "colab_type": "text"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- What is the drawback of using the **train/test split** procedure for model evaluation?\n",
        "- How does **K-fold cross-validation** overcome this limitation?\n",
        "- How can cross-validation be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**?\n",
        "- What are some possible **improvements** to cross-validation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CBDUOgyXXmi",
        "colab_type": "text"
      },
      "source": [
        "## Review of model evaluation procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E15D-WsSXXmj",
        "colab_type": "text"
      },
      "source": [
        "**Motivation:** Need a way to choose between machine learning models\n",
        "\n",
        "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
        "\n",
        "**Initial idea:** Train and test on the same data\n",
        "\n",
        "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
        "\n",
        "**Alternative idea:** Train/test split\n",
        "\n",
        "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
        "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
        "- But, it provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raROHAeaXXmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8x0JyppXXmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the iris data\n",
        "iris = load_iris()\n",
        "\n",
        "# create X (features) and y (response)\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbDnx1qSXXmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use train/test split with different random_state values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4)\n",
        "\n",
        "# check classification accuracy of KNN with K=5\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkPmTPJWXXms",
        "colab_type": "text"
      },
      "source": [
        "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
        "\n",
        "**Answer:** That's the essense of cross-validation!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu4dBj_VXXmt",
        "colab_type": "text"
      },
      "source": [
        "## Steps for K-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpUazu3tXXmt",
        "colab_type": "text"
      },
      "source": [
        "1. Split the dataset into K **equal** partitions (or \"folds\").\n",
        "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**.\n",
        "3. Calculate **testing accuracy**.\n",
        "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time.\n",
        "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7ULC-ARXXmu",
        "colab_type": "text"
      },
      "source": [
        "Diagram of **5-fold cross-validation:**\n",
        "\n",
        "![5-fold cross-validation](https://github.com/justmarkham/scikit-learn-videos/blob/master/images/07_cross_validation_diagram.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvqW2XmXXmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# simulate splitting a dataset of 25 observations into 5 folds\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=False).split(range(25))\n",
        "\n",
        "# print the contents of each training and testing set\n",
        "print('{} {:^61} {}'.format('Iteration', 'Training set observations', 'Testing set observations'))\n",
        "for iteration, data in enumerate(kf, start=1):\n",
        "    print('{:^9} {} {:^25}'.format(iteration, data[0], str(data[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZRCJEWTXXmw",
        "colab_type": "text"
      },
      "source": [
        "- Dataset contains **25 observations** (numbered 0 through 24)\n",
        "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
        "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
        "- Every observation is in the testing set **exactly once**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqOPPheQXXmx",
        "colab_type": "text"
      },
      "source": [
        "## Comparing cross-validation to train/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0ex4GyOXXmx",
        "colab_type": "text"
      },
      "source": [
        "Advantages of **cross-validation:**\n",
        "\n",
        "- More accurate estimate of out-of-sample accuracy\n",
        "- More \"efficient\" use of data (every observation is used for both training and testing)\n",
        "\n",
        "Advantages of **train/test split:**\n",
        "\n",
        "- Runs K times faster than K-fold cross-validation\n",
        "- Simpler to examine the detailed results of the testing process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN5hR0K8XXmy",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation recommendations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAgOMhVEXXmy",
        "colab_type": "text"
      },
      "source": [
        "1. K can be any number, but **K=10** is generally recommended\n",
        "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
        "    - Each response class should be represented with equal proportions in each of the K folds\n",
        "    - scikit-learn's `cross_val_score` function does this by default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbiDEwldXXmz",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation example: parameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNx5Zx31XXm0",
        "colab_type": "text"
      },
      "source": [
        "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQXRkePEXXm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUOKtSQfXXm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StkNdlPQXXm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use average accuracy as an estimate of out-of-sample accuracy\n",
        "print(scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0UUXA28XXm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# search for an optimal value of K for KNN\n",
        "k_range = list(range(1, 31))\n",
        "k_scores = []\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "    k_scores.append(scores.mean())\n",
        "print(k_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYc3gafaXXm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qya_iwYXXm9",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation example: model selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4vHWfXiXXm9",
        "colab_type": "text"
      },
      "source": [
        "**Goal:** Compare the best KNN model with logistic regression on the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgKR7VnrXXm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with the best KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=20)\n",
        "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1oaH6YyXXnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaPj02fjXXnB",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation example: feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wj9qU11XXnC",
        "colab_type": "text"
      },
      "source": [
        "**Goal**: Select whether the Newspaper feature should be included in the linear regression model on the advertising dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN297WQeXXnD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHh6u30gXXnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the advertising dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/justmarkham/\\\n",
        "scikit-learn-videos/master/data/Advertising.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnrPMTj6XXnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a Python list of three feature names\n",
        "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
        "\n",
        "# use the list to select a subset of the DataFrame (X)\n",
        "X = data[feature_cols]\n",
        "\n",
        "# select the Sales column as the response (y)\n",
        "y = data.Sales"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7cCNquyXXnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with all three features\n",
        "lm = LinearRegression()\n",
        "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enBdNWMgXXnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix the sign of MSE scores\n",
        "mse_scores = -scores\n",
        "print(mse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDwN3EHRXXnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert from MSE to RMSE\n",
        "rmse_scores = np.sqrt(mse_scores)\n",
        "print(rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHcBOCyzXXnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the average RMSE\n",
        "print(rmse_scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aEtX6c-XXnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with two features (excluding Newspaper)\n",
        "feature_cols = ['TV', 'Radio']\n",
        "X = data[feature_cols]\n",
        "print(np.sqrt(-cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnf8N7j9XXnV",
        "colab_type": "text"
      },
      "source": [
        "## Improvements to cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Yi5arbXXnV",
        "colab_type": "text"
      },
      "source": [
        "**Repeated cross-validation**\n",
        "\n",
        "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
        "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
        "\n",
        "**Creating a hold-out set**\n",
        "\n",
        "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
        "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
        "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
        "\n",
        "**Feature engineering and selection within cross-validation iterations**\n",
        "\n",
        "- Normally, feature engineering and selection occurs **before** cross-validation\n",
        "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
        "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZD3dXf1XXnW",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
        "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
        "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0&list=PL5-da3qGB5IA6E6ZNXu7dp89_uv8yocmf) (10 minutes)\n",
        "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
        "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
        "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
        "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
      ]
    }
  ]
}