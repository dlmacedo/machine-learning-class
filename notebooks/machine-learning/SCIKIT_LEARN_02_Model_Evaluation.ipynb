{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SCIKIT_LEARN_02_Model_Evaluation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlmacedo/maxtrack/blob/master/notebooks/machine-learning/SCIKIT_LEARN_02_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6BjxD_0FowF",
        "colab_type": "text"
      },
      "source": [
        "# Comparing machine learning models in scikit-learn\n",
        "\n",
        "Created by [Data School](http://www.dataschool.io/). Modified by [David MacÃªdo](https://github.com/dlmacedo). **Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9JEah3KFowI",
        "colab_type": "text"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- How do I choose **which model to use** for my supervised learning task?\n",
        "- How do I choose the **best tuning parameters** for that model?\n",
        "- How do I estimate the **likely performance of my model** on out-of-sample data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0atPPY_FowJ",
        "colab_type": "text"
      },
      "source": [
        "## Review\n",
        "\n",
        "- Classification task: Predicting the species of an unknown iris\n",
        "- Used three classification models: KNN (K=1), KNN (K=5), logistic regression\n",
        "- Need a way to choose between the models\n",
        "\n",
        "**Solution:** Model evaluation procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JkKJO1PFowK",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation procedure #1: Train and test on the entire dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV6QLquPFowL",
        "colab_type": "text"
      },
      "source": [
        "1. Train the model on the **entire dataset**.\n",
        "2. Test the model on the **same dataset**, and evaluate how well we did by comparing the **predicted** response values with the **true** response values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fZ-53ZtFowM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the iris data\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "# create X (features) and y (response)\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chNWSyekFowP",
        "colab_type": "text"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1Sm5E-FowQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# fit the model with data\n",
        "logreg.fit(X, y)\n",
        "\n",
        "# predict the response values for the observations in X\n",
        "logreg.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVAdHmw7FowT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store the predicted response values\n",
        "y_pred = logreg.predict(X)\n",
        "\n",
        "# check how many predictions were generated\n",
        "len(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6A07GgbFowV",
        "colab_type": "text"
      },
      "source": [
        "Classification accuracy:\n",
        "\n",
        "- **Proportion** of correct predictions\n",
        "- Common **evaluation metric** for classification problems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcLL-kunFowW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute classification accuracy for the logistic regression model\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBmGHNzwFowY",
        "colab_type": "text"
      },
      "source": [
        "- Known as **training accuracy** when you train and test the model on the same data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqTMno66FowY",
        "colab_type": "text"
      },
      "source": [
        "### KNN (K=5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Oxg3yaFowZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X, y)\n",
        "y_pred = knn.predict(X)\n",
        "print(metrics.accuracy_score(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uopNR4rlFowb",
        "colab_type": "text"
      },
      "source": [
        "### KNN (K=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ3yz9i-Fowb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X, y)\n",
        "y_pred = knn.predict(X)\n",
        "print(metrics.accuracy_score(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJviKWnFowd",
        "colab_type": "text"
      },
      "source": [
        "### Problems with training and testing on the same data\n",
        "\n",
        "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
        "- But, maximizing training accuracy rewards **overly complex models** that won't necessarily generalize\n",
        "- Unnecessarily complex models **overfit** the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY7124d_Fowf",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation procedure #2: Train/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7Ct12zIFowg",
        "colab_type": "text"
      },
      "source": [
        "1. Split the dataset into two pieces: a **training set** and a **testing set**.\n",
        "2. Train the model on the **training set**.\n",
        "3. Test the model on the **testing set**, and evaluate how well we did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHC4jUcsFowg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the shapes of X and y\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIVtBa5pFowi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEP 1: split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428BblqlFowk",
        "colab_type": "text"
      },
      "source": [
        "![Train/test split](https://github.com/justmarkham/scikit-learn-videos/blob/master/images/05_train_test_split.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ-4SqjFFowl",
        "colab_type": "text"
      },
      "source": [
        "What did this accomplish?\n",
        "\n",
        "- Model can be trained and tested on **different data**\n",
        "- Response values are known for the testing set, and thus **predictions can be evaluated**\n",
        "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lxh2YRsFowl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the shapes of the new X objects\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7qGynuWFown",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the shapes of the new y objects\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N7fiUXUFowp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEP 2: train the model on the training set\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xkwX3YVFowr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEP 3: make predictions on the testing set\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# compare actual response values (y_test) with predicted response values (y_pred)\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeUQU0VLFowt",
        "colab_type": "text"
      },
      "source": [
        "Repeat for KNN with K=5:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5GnoZqMFowu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4hldQr0Fowv",
        "colab_type": "text"
      },
      "source": [
        "Repeat for KNN with K=1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG4-Pbt0Foww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbwGzVFUFowy",
        "colab_type": "text"
      },
      "source": [
        "Can we locate an even better value for K?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-_8Dz8Fowy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# try K=1 through K=25 and record testing accuracy\n",
        "k_range = list(range(1, 26))\n",
        "scores = []\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    scores.append(metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbdTI6T_Fow1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import Matplotlib (scientific plotting library)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# allow plots to appear within the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# plot the relationship between K and testing accuracy\n",
        "plt.plot(k_range, scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Testing Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqAU1GadFow3",
        "colab_type": "text"
      },
      "source": [
        "- **Training accuracy** rises as model complexity increases\n",
        "- **Testing accuracy** penalizes models that are too complex or not complex enough\n",
        "- For KNN models, complexity is determined by the **value of K** (lower value = more complex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "652NOIOsFow4",
        "colab_type": "text"
      },
      "source": [
        "## Making predictions on out-of-sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2FIlOvdFow4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the model with the best known parameters\n",
        "knn = KNeighborsClassifier(n_neighbors=11)\n",
        "\n",
        "# train the model with X and y (not X_train and y_train)\n",
        "knn.fit(X, y)\n",
        "\n",
        "# make a prediction for an out-of-sample observation\n",
        "knn.predict([[3, 5, 4, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KnDq-zoFow6",
        "colab_type": "text"
      },
      "source": [
        "## Downsides of train/test split?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsxxbUdFow6",
        "colab_type": "text"
      },
      "source": [
        "- Provides a **high-variance estimate** of out-of-sample accuracy\n",
        "- **K-fold cross-validation** overcomes this limitation\n",
        "- But, train/test split is still useful because of its **flexibility and speed**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18xHMXoXFow7",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- Quora: [What is an intuitive explanation of overfitting?](http://www.quora.com/What-is-an-intuitive-explanation-of-overfitting/answer/Jessica-Su)\n",
        "- Video: [Estimating prediction error](https://www.youtube.com/watch?v=_2ij6eaaSl0&t=2m34s) (12 minutes, starting at 2:34) by Hastie and Tibshirani\n",
        "- [Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
        "    - [Guiding questions](https://github.com/justmarkham/DAT8/blob/master/homework/09_bias_variance.md) when reading this article\n",
        "- Video: [Visualizing bias and variance](http://work.caltech.edu/library/081.html) (15 minutes) by Abu-Mostafa"
      ]
    }
  ]
}