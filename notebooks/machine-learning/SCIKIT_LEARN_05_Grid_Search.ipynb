{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SCIKIT_LEARN_05_Grid_Search.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlmacedo/maxtrack/blob/master/notebooks/machine-learning/SCIKIT_LEARN_05_Grid_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xel16X2VZ1ao",
        "colab_type": "text"
      },
      "source": [
        "# Efficiently searching for optimal tuning parameters\n",
        "\n",
        "Created by [Data School](http://www.dataschool.io/). Modified by [David MacÃªdo](https://github.com/dlmacedo). **Note:** This notebook uses Python 3.6 and scikit-learn 0.19.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85hNyI2Z1ar",
        "colab_type": "text"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "- How can K-fold cross-validation be used to search for an **optimal tuning parameter**?\n",
        "- How can this process be made **more efficient**?\n",
        "- How do you search for **multiple tuning parameters** at once?\n",
        "- What do you do with those tuning parameters before making **real predictions**?\n",
        "- How can the **computational expense** of this process be reduced?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnm9uuncZ1as",
        "colab_type": "text"
      },
      "source": [
        "## Review of K-fold cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S_dKeQZZ1at",
        "colab_type": "text"
      },
      "source": [
        "Steps for cross-validation:\n",
        "\n",
        "- Dataset is split into K \"folds\" of **equal size**\n",
        "- Each fold acts as the **testing set** 1 time, and acts as the **training set** K-1 times\n",
        "- **Average testing performance** is used as the estimate of out-of-sample performance\n",
        "\n",
        "Benefits of cross-validation:\n",
        "\n",
        "- More **reliable** estimate of out-of-sample performance than train/test split\n",
        "- Can be used for selecting **tuning parameters**, choosing between **models**, and selecting **features**\n",
        "\n",
        "Drawbacks of cross-validation:\n",
        "\n",
        "- Can be computationally **expensive**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZi_IeYeZ1au",
        "colab_type": "text"
      },
      "source": [
        "## Review of parameter tuning using `cross_val_score`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnxvXuGNZ1av",
        "colab_type": "text"
      },
      "source": [
        "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFbjk4S_Z1aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp-0qjlqZ1az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the iris data\n",
        "iris = load_iris()\n",
        "\n",
        "# create X (features) and y (response)\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etDVpKE4Z1a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNPYngZeZ1a4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use average accuracy as an estimate of out-of-sample accuracy\n",
        "print(scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_OyUEYbZ1a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# search for an optimal value of K for KNN\n",
        "k_range = list(range(1, 31))\n",
        "k_scores = []\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
        "    k_scores.append(scores.mean())\n",
        "print(k_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDKUyvqzZ1a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "plt.plot(k_range, k_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piQ24CGrZ1a-",
        "colab_type": "text"
      },
      "source": [
        "## More efficient parameter tuning using `GridSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic-zLX09Z1a_",
        "colab_type": "text"
      },
      "source": [
        "Allows you to define a **grid of parameters** that will be **searched** using K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_VuLeDmZ1a_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRWAp8DCZ1bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the parameter values that should be searched\n",
        "k_range = list(range(1, 31))\n",
        "print(k_range)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNzFfWKvZ1bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a parameter grid: map the parameter names to the values that should be searched\n",
        "param_grid = dict(n_neighbors=k_range)\n",
        "print(param_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9un4KnxZ1bG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate the grid\n",
        "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkZZ8tROZ1bK",
        "colab_type": "text"
      },
      "source": [
        "- You can set **`n_jobs = -1`** to run computations in parallel (if supported by your computer and OS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmcZ-1djZ1bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the grid with data\n",
        "grid.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMMMZumZ1bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view the results as a pandas DataFrame\n",
        "import pandas as pd\n",
        "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue70lQQoZ1bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine the first result\n",
        "print(grid.cv_results_['params'][0])\n",
        "print(grid.cv_results_['mean_test_score'][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmc2DTK5Z1bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the array of mean scores only\n",
        "grid_mean_scores = grid.cv_results_['mean_test_score']\n",
        "print(grid_mean_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suWdC8IWZ1bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the results\n",
        "plt.plot(k_range, grid_mean_scores)\n",
        "plt.xlabel('Value of K for KNN')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE3oRmZyZ1bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine the best model\n",
        "print(grid.best_score_)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_estimator_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIqzkK6rZ1bV",
        "colab_type": "text"
      },
      "source": [
        "## Searching multiple parameters simultaneously"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3R4kPIhZ1bV",
        "colab_type": "text"
      },
      "source": [
        "- **Example:** tuning `max_depth` and `min_samples_leaf` for a `DecisionTreeClassifier`\n",
        "- Could tune parameters **independently**: change `max_depth` while leaving `min_samples_leaf` at its default value, and vice versa\n",
        "- But, best performance might be achieved when **neither parameter** is at its default value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Gp-AzKZ1bW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the parameter values that should be searched\n",
        "k_range = list(range(1, 31))\n",
        "weight_options = ['uniform', 'distance']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcDICPU5Z1bZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a parameter grid: map the parameter names to the values that should be searched\n",
        "param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
        "print(param_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtdUhba_Z1bb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate and fit the grid\n",
        "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
        "grid.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNguqtD1Z1bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# view the results\n",
        "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB2uRwvKZ1bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine the best model\n",
        "print(grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWkAwYjaZ1bg",
        "colab_type": "text"
      },
      "source": [
        "## Using the best parameters to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inJX_YLkZ1bh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train your model using all data and the best known parameters\n",
        "knn = KNeighborsClassifier(n_neighbors=13, weights='uniform')\n",
        "knn.fit(X, y)\n",
        "\n",
        "# make a prediction on out-of-sample data\n",
        "knn.predict([[3, 5, 4, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8F5rHKOZ1bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shortcut: GridSearchCV automatically refits the best model using all of the data\n",
        "grid.predict([[3, 5, 4, 2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogobMqJGZ1bk",
        "colab_type": "text"
      },
      "source": [
        "## Reducing computational expense using `RandomizedSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2X_oI0uZ1bk",
        "colab_type": "text"
      },
      "source": [
        "- Searching many different parameters at once may be computationally infeasible\n",
        "- `RandomizedSearchCV` searches a subset of the parameters, and you control the computational \"budget\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W7vn0EYZ1bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh2jR0N3Z1bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify \"parameter distributions\" rather than a \"parameter grid\"\n",
        "param_dist = dict(n_neighbors=k_range, weights=weight_options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGCjEBKNZ1bp",
        "colab_type": "text"
      },
      "source": [
        "- **Important:** Specify a continuous distribution (rather than a list of values) for any continous parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOwdBrrUZ1bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n_iter controls the number of searches\n",
        "rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, random_state=5, return_train_score=False)\n",
        "rand.fit(X, y)\n",
        "pd.DataFrame(rand.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb7OKmbPZ1bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# examine the best model\n",
        "print(rand.best_score_)\n",
        "print(rand.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfSVik-FZ1bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run RandomizedSearchCV 20 times (with n_iter=10) and record the best score\n",
        "best_scores = []\n",
        "for _ in range(20):\n",
        "    rand = RandomizedSearchCV(knn, param_dist, cv=10, scoring='accuracy', n_iter=10, return_train_score=False)\n",
        "    rand.fit(X, y)\n",
        "    best_scores.append(round(rand.best_score_, 3))\n",
        "print(best_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2mBr_VMZ1bw",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- scikit-learn documentation: [Grid search](http://scikit-learn.org/stable/modules/grid_search.html), [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "- Timed example: [Comparing randomized search and grid search](http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
        "- scikit-learn workshop by Andreas Mueller: [Video segment on randomized search](https://youtu.be/0wUF_Ov8b0A?t=17m38s) (3 minutes), [related notebook](https://github.com/amueller/pydata-nyc-advanced-sklearn/blob/master/Chapter%203%20-%20Randomized%20Hyper%20Parameter%20Search.ipynb)\n",
        "- Paper by Yoshua Bengio: [Random Search for Hyper-Parameter Optimization](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)"
      ]
    }
  ]
}